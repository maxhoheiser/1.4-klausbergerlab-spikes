{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import scipy.stats as st\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "import platform\n",
    "import qgrid\n",
    "import datetime\n",
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from numba import njit\n",
    "\n",
    "from sync_class import SyncPhenosys\n",
    "from eda_class import SpikesEDA\n",
    "from behavior_class import BehaviorAnalysis\n",
    "from sda_class import SpikesSDA\n",
    "from report_class import SpikesReport\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#pd.set_option('display.max_columns', 100)\n",
    "#pd.set_option('display.max_rows', 100)\n",
    "\n",
    "%matplotlib notebook\n",
    "#plt.style.use('ggplot')\n",
    "#plt.style.use('gadfly.mplstyle')\n",
    "\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "#plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle\")\n",
    "\n",
    "\n",
    "#from IPython.core.display import display, HTML\n",
    "#display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "# dark theme\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================================================================\n",
    "# specify file path & sessions\n",
    "\n",
    "windows_folder = r\"C:/Users/User/Google Drive/3 Projekte/Masterarbeit Laborarbeit Neuroscience/1 Data Analysis\"\n",
    "linux_folder = \"/home/max/ExpanDrive/Google Drive/3 Projekte/Masterarbeit Laborarbeit Neuroscience/1 Data Analysis\"\n",
    "mac_folder = \"/Users/max/Google Drive/3 Projekte/Masterarbeit Laborarbeit Neuroscience/1 Data Analysis\"\n",
    "\n",
    "# list -> [ session_name, [ttl_missing_rows], load_spikes, [spikes_trials_skip] ]\n",
    "se_li = [('JG14_190621', [1900,1931,1996,2058,2127],True,[(0,6),(215,'end')]),\n",
    "         ('JG14_190619', [111, 2781],False,[]),\n",
    "         ('JG14_190626', [1428, 1824, 1838, 2861, 2910, 3089, 3245, 3430, 3443],False,[]),\n",
    "         ('JG15_190722', [2094, 2574, 2637, 2808, 2831, 3499],False,[]),\n",
    "         ('JG15_190725', [366,711,1487,1578,1659,2221,2666,2720,2769,2847,3371,3476],False,[]),\n",
    "         ('JG18a_190814', [405,2621,2693,2770,2959,3015,3029,3038,3048],False,[]),\n",
    "         ('JG18b_190828', [1744, 2363, 2648, 2701, 2731, 2778,2953,2967],True,[]),\n",
    "         ]\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================================================================\n",
    "# Load sessions functions\n",
    "\n",
    "def add_session(session, gamble_side, sync_obj, missing_rows_ttl, combined, trials, behavior, spikes, trials_skip):\n",
    "    session_dict = {\n",
    "        'session':session,\n",
    "        'gamble_side':gamble_side,\n",
    "        #'sync_obj':sync_obj,\n",
    "        'missing_rows_ttl':missing_rows_ttl,\n",
    "        'combined':combined,\n",
    "        'trials':trials,\n",
    "        'behavior':behavior,\n",
    "        'trials_skip':trials_skip,\n",
    "    }\n",
    "    if spikes != False:\n",
    "        session_dict['spikes']=spikes\n",
    "        \n",
    "    # add session dict to all sessions dict\n",
    "    all_sessions_dict[session]=session_dict\n",
    "    return session_dict\n",
    "\n",
    "\n",
    "def load_session(session, missing_rows_ttl=[], lo_spikes=False, trials_skip=[]):\n",
    "\n",
    "    # load calss and set folder depending on platform\n",
    "\n",
    "    # load calss and set folder depending on platform\n",
    "    if platform.system() == 'Linux':\n",
    "        # Linux\n",
    "        folder = linux_folder + '/' + session\n",
    "    elif platform.system() == 'Windows':\n",
    "        # windows\n",
    "        folder = windows_folder + r\"/\" + session\n",
    "    elif platform.system() == 'Darwin':\n",
    "        folder = mac_folder + r\"/\" + session\n",
    "\n",
    "    sync_obj = SyncPhenosys(session, folder, 7, 1, rows_missing_ttl)   \n",
    "    gamble_side = sync_obj.gamble_side\n",
    "\n",
    "    # first find missing rows\n",
    "    #missing_rows_csv = []\n",
    "    #combined = sync_obj.combine_dataframes(missing_rows_ttl, missing_rows_csv, 'channel 1', sync_obj.csv, False)\n",
    "    #trials_df = sync_obj.get_trials(combined)\n",
    "    behavior_obj = BehaviorAnalysis(sync_obj, deselect_trials)\n",
    "    \n",
    "    if lo_spikes:\n",
    "        spikes_obj = SpikeAnalysis(behavior_obj)\n",
    "    #    spikes = SpikeAnalysis(session, folder, sync_obj)\n",
    "    #    for a,b in trials_skip:\n",
    "    #        if b == 'end':\n",
    "    #            spikes.trials_df.loc[a:,'select'] = False\n",
    "    #        else:\n",
    "    #            spikes.trials_df.loc[a:b,'select'] = False\n",
    "    #else:\n",
    "    #    spikes = False\n",
    "\n",
    "    return session, gamble_side, sync_obj, behavior_obj, spikes_obj\n",
    "\n",
    "\n",
    "def load_all_sessions(se_li):\n",
    "    all_sessions = dict()\n",
    "    for session, missing_rows_ttl, lo_spikes, trials_skip in se_li:\n",
    "        session, gamble_side, sync_obj, combined, trials, behavior, spikes = load_session(session, missing_rows_ttl, lo_spikes, trials_skip)\n",
    "        \n",
    "        session_dict = add_session(session, gamble_side, sync_obj, missing_rows_ttl, combined, trials, behavior, spikes, trials_skip)  \n",
    "        all_sessions[session]=session_dict\n",
    "\n",
    "    return all_sessions\n",
    "\n",
    "\n",
    "        \n",
    "# ============================================================================================================================\n",
    "# save & load sessions from pickl functions\n",
    "\n",
    "# save dict to pickl\n",
    "def save_all_sessions_dict_pickl():\n",
    "    if platform.system() == 'Linux':\n",
    "        # Linux\n",
    "        folder = linux_folder\n",
    "    elif platform.system() == 'Windows':\n",
    "        # windows\n",
    "        folder = windows_folder\n",
    "    elif platform.system() == 'Darwin':\n",
    "        folder = mac_folder \n",
    "        \n",
    "    file = folder + '/all_sessions_dict.pkl'\n",
    "    with open(file, 'wb') as dump:\n",
    "        pickle.dump(all_sessions_dict, dump)\n",
    "\n",
    "# load dict from pickl\n",
    "def load_all_sessions_dict_pickl():\n",
    "    if platform.system() == 'Linux':\n",
    "        # Linux\n",
    "        folder = linux_folder\n",
    "    elif platform.system() == 'Windows':\n",
    "        # windows\n",
    "        folder = windows_folder\n",
    "    elif platform.system() == 'Darwin':\n",
    "        folder = mac_folder \n",
    "        \n",
    "    file = folder + '/all_sessions_dict.pkl'\n",
    "    \n",
    "    with open(file, 'rb') as dump:\n",
    "        all_sessions_dict = pickle.load(dump)\n",
    "    return all_sessions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JG14_190621"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spikes/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2382: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  result = fn(*args, **kwargs)\n",
      "/opt/anaconda3/envs/spikes/lib/python3.8/site-packages/pandas/core/indexing.py:1719: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "/Users/max/Google Drive/3.1 Code Repository/3 Masterarbeit/Spikes/sda_class.py:246: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  reward_aligned_ar[cl,:]=np.array(get_spikes_in_window_all_trials_singlevent(self.spikes_per_cluster_ar[cl], trials_ar[:,2], delta))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 40s, sys: 4.89 s, total: 6min 45s\n",
      "Wall time: 6min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "session = 'JG14_190621'\n",
    "folder = mac_folder + r\"/\" + session\n",
    "# sync\n",
    "rows_missing_ttl = [1900,1931,1996,2058,2127]\n",
    "# behavior\n",
    "deselect_trials = [(0,6),(215,'end')]\n",
    "# sda\n",
    "window = 2000\n",
    "iterations = 1000\n",
    "bins = 50\n",
    "\n",
    "sync_obj = SyncPhenosys(session, folder, 7, 1, rows_missing_ttl) \n",
    "behavior_obj = BehaviorAnalysis(sync_obj, deselect_trials)\n",
    "eda_obj = SpikesEDA(behavior_obj)\n",
    "sda_obj = SpikesSDA(eda_obj)\n",
    "sda_obj.spiketimes_data_ar, sda_obj.reward_aligned_ar, sda_obj.binned, sda_obj.mean_ar, sda_obj.percentil_ar = sda_obj.get_bootstrap_all_clusters(window, iterations,bins,'reward')\n",
    "report_obj = SpikesReport(eda_obj)\n",
    "\n",
    "JG14_190621 = type('obj', (object,), \n",
    "                   {'sync':sync_obj,\n",
    "                    'behavior':behavior_obj,\n",
    "                    'eda':eda_obj,\n",
    "                    'sda': sda_obj,\n",
    "                    'report': report_obj,\n",
    "                   })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#JG14_190621.eda.generate_plots()\n",
    "#JG14_190621.sda.generate_plots()\n",
    "JG14_190621.report.generate_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JG18b_190828"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spikes/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2382: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  result = fn(*args, **kwargs)\n",
      "/opt/anaconda3/envs/spikes/lib/python3.8/site-packages/pandas/core/indexing.py:1719: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "/Users/max/Google Drive/3.1 Code Repository/3 Masterarbeit/Spikes/sda_class.py:246: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  reward_aligned_ar[cl,:]=np.array(get_spikes_in_window_all_trials_singlevent(self.spikes_per_cluster_ar[cl], trials_ar[:,2], delta))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 28s, sys: 13.8 s, total: 17min 42s\n",
      "Wall time: 17min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "session = 'JG18b_190828'\n",
    "folder = mac_folder + r\"/\" + session\n",
    "# sync\n",
    "rows_missing_ttl = [1744, 2363, 2648, 2701, 2731, 2778,2953,2967]\n",
    "# behavior\n",
    "deselect_trials = [(0,0),(204,'end')]\n",
    "# eda\n",
    "skip_clusters = [116, 280]\n",
    "# sda\n",
    "window = 2000\n",
    "iterations = 1000\n",
    "bins = 50\n",
    "\n",
    "sync_obj = SyncPhenosys(session, folder, 7, 1, rows_missing_ttl) \n",
    "behavior_obj = BehaviorAnalysis(sync_obj, deselect_trials)\n",
    "eda_obj = SpikesEDA(behavior_obj)\n",
    "sda_obj = SpikesSDA(eda_obj)\n",
    "sda_obj.spiketimes_data_ar, sda_obj.reward_aligned_ar, sda_obj.binned, sda_obj.mean_ar, sda_obj.percentil_ar = sda_obj.get_bootstrap_all_clusters(window, iterations,bins,'reward')\n",
    "report_obj = SpikesReport(eda_obj)\n",
    "\n",
    "JG18b_190828 = type('obj', (object,), \n",
    "                   {'sync':sync_obj,\n",
    "                    'behavior':behavior_obj,\n",
    "                    'eda':eda_obj,\n",
    "                    'sda': sda_obj,\n",
    "                    'report': report_obj,\n",
    "                   })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#JG18b_190828.eda.generate_plots()\n",
    "JG18b_190828.sda.generate_plots(window,iterations,bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "JG18b_190828.report.generate_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
